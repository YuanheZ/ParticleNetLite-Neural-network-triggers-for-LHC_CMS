{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward0\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import awkward\n",
    "import awkward0\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbors\n",
    "construct graph data using knn algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_distance_matrix_general(A, B):\n",
    "    with tf.name_scope('dmat'):\n",
    "        r_A = tf.reduce_sum(A * A, axis=2, keepdims=True)\n",
    "        r_B = tf.reduce_sum(B * B, axis=2, keepdims=True)\n",
    "        m = tf.matmul(A, tf.transpose(B, perm=(0, 2, 1)))\n",
    "        D = r_A - 2 * m + tf.transpose(r_B, perm=(0, 2, 1))\n",
    "        return D\n",
    "\n",
    "\n",
    "def knn(num_points, k, topk_indices, features):\n",
    "    # topk_indices: (N, P, K)\n",
    "    # features: (N, P, C)\n",
    "    with tf.name_scope('knn'):\n",
    "        queries_shape = tf.shape(features)\n",
    "        batch_size = queries_shape[0]\n",
    "        batch_indices = tf.tile(tf.reshape(tf.range(batch_size), (-1, 1, 1, 1)), (1, num_points, k, 1))\n",
    "        indices = tf.concat([batch_indices, tf.expand_dims(topk_indices, axis=3)], axis=3)  # (N, P, K, 2)\n",
    "        return tf.gather_nd(features, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Convulution operation\n",
    "Attention: use (1,1) kernel Conv2D to perform MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_conv(points, features, num_points, K, channels, with_bn=True, activation='relu', pooling='average', name='edgeconv'):\n",
    "    \"\"\"EdgeConv\n",
    "    Args:\n",
    "        K: int, number of neighbors\n",
    "        in_channels: # of input channels\n",
    "        channels: tuple of output channels\n",
    "        pooling: pooling method ('max' or 'average')\n",
    "    Inputs:\n",
    "        points: (N, P, C_p)\n",
    "        features: (N, P, C_0)\n",
    "    Returns:\n",
    "        transformed points: (N, P, C_out), C_out = channels[-1]\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope('edgeconv'):\n",
    "\n",
    "        # distance\n",
    "        D = batch_distance_matrix_general(points, points)  # (N, P, P)\n",
    "        _, indices = tf.nn.top_k(-D, k=K + 1)  # (N, P, K+1)\n",
    "        indices = indices[:, :, 1:]  # (N, P, K)\n",
    "\n",
    "        fts = features\n",
    "        knn_fts = knn(num_points, K, indices, fts)  # (N, P, K, C)\n",
    "        knn_fts_center = tf.tile(tf.expand_dims(fts, axis=2), (1, 1, K, 1))  # (N, P, K, C)\n",
    "        knn_fts = tf.concat([knn_fts_center, tf.subtract(knn_fts, knn_fts_center)], axis=-1)  # (N, P, K, 2*C)\n",
    "\n",
    "        x = knn_fts\n",
    "        for idx, channel in enumerate(channels):\n",
    "            x = keras.layers.Conv2D(channel, kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "                                    use_bias=False if with_bn else True, kernel_initializer='HeNormal', name='%s_conv%d' % (name, idx))(x)\n",
    "            if with_bn:\n",
    "                x = keras.layers.BatchNormalization(name='%s_bn%d' % (name, idx))(x)\n",
    "            if activation:\n",
    "                x = keras.layers.Activation(activation, name='%s_act%d' % (name, idx))(x)\n",
    "\n",
    "        if pooling == 'max':\n",
    "            fts = tf.reduce_max(x, axis=2)  # (N, P, C')\n",
    "        else:\n",
    "            fts = tf.reduce_mean(x, axis=2)  # (N, P, C')\n",
    "\n",
    "        # shortcut\n",
    "        sc = keras.layers.Conv2D(channels[-1], kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "                                 use_bias=False if with_bn else True, kernel_initializer='HeNormal', name='%s_sc_conv' % name)(tf.expand_dims(features, axis=2))\n",
    "        if with_bn:\n",
    "            sc = keras.layers.BatchNormalization(name='%s_sc_bn' % name)(sc)\n",
    "        sc = tf.squeeze(sc, axis=2)\n",
    "\n",
    "        if activation:\n",
    "            return keras.layers.Activation(activation, name='%s_sc_act' % name)(sc + fts)  # (N, P, C')\n",
    "        else:\n",
    "            return sc + fts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParticleNetLite++\n",
    "Base architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _particle_net_base(points, features=None, mask=None, setting=None, name='particle_net'):\n",
    "    # points : (N, P, C_coord)\n",
    "    # features:  (N, P, C_features), optional\n",
    "    # mask: (N, P, 1), optinal\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        if features is None:\n",
    "            features = points\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(tf.not_equal(mask, 0), dtype='float32')  # 1 if valid\n",
    "            coord_shift = tf.multiply(999., tf.cast(tf.equal(mask, 0), dtype='float32'))  # make non-valid positions to 99\n",
    "\n",
    "        fts = tf.squeeze(keras.layers.BatchNormalization(name='%s_fts_bn' % name)(tf.expand_dims(features, axis=2)), axis=2)\n",
    "        for layer_idx, layer_param in enumerate(setting.conv_params):\n",
    "            K, channels = layer_param\n",
    "            pts = tf.add(coord_shift, points) if layer_idx == 0 else tf.add(coord_shift, fts)\n",
    "            fts = edge_conv(pts, fts, setting.num_points, K, channels, with_bn=True, activation='relu',\n",
    "                            pooling=setting.conv_pooling, name='%s_%s%d' % (name, 'EdgeConv', layer_idx))\n",
    "\n",
    "        if mask is not None:\n",
    "            fts = tf.multiply(fts, mask)\n",
    "\n",
    "        pool = tf.reduce_mean(fts, axis=1)  # (N, C)\n",
    "\n",
    "        if setting.fc_params is not None:\n",
    "            x = pool\n",
    "            for layer_idx, layer_param in enumerate(setting.fc_params):\n",
    "                units, drop_rate = layer_param\n",
    "                x = keras.layers.Dense(units, activation='relu')(x)\n",
    "                if drop_rate is not None and drop_rate > 0:\n",
    "                    x = keras.layers.Dropout(drop_rate)(x)\n",
    "            out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "            return out  # (N, num_classes)\n",
    "        else:\n",
    "            return pool\n",
    "\n",
    "class _DotDict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParticleNetLite++\n",
    "Change parameters here:\n",
    "\n",
    "1. number of neighbors of knn\n",
    "\n",
    "2. params of MLP in EdgeConv\n",
    "\n",
    "3. Global pooling operation\n",
    "\n",
    "4. number of neurons in dense layer\n",
    "\n",
    "5. dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_particle_net_lite(num_classes, input_shapes):\n",
    "    r\"\"\"\n",
    "    num_classes : int\n",
    "        Number of output classes.\n",
    "    input_shapes : dict\n",
    "        The shapes of each input (`points`, `features`, `mask`).\n",
    "    \"\"\"\n",
    "    setting = _DotDict()\n",
    "    setting.num_class = num_classes\n",
    "    # conv_params: list of tuple in the format (K, (C1, C2, C3))\n",
    "    setting.conv_params = [\n",
    "        (7, (4, 4, 4)),\n",
    "        (7, (8, 8, 8)),\n",
    "        ]\n",
    "    # conv_pooling: 'average' or 'max'\n",
    "    setting.conv_pooling = 'average'\n",
    "    # fc_params: list of tuples in the format (C, drop_rate)\n",
    "    setting.fc_params = [(16, None)]\n",
    "    setting.num_points = input_shapes['points'][0]\n",
    "\n",
    "    points = keras.Input(name='points', shape=input_shapes['points'])\n",
    "    features = keras.Input(name='features', shape=input_shapes['features']) if 'features' in input_shapes else None\n",
    "    mask = keras.Input(name='mask', shape=input_shapes['mask']) if 'mask' in input_shapes else None\n",
    "    outputs = _particle_net_base(points, features, mask, setting, name='ParticleNet')\n",
    "\n",
    "    return keras.Model(inputs=[points, features, mask], outputs=outputs, name='ParticleNet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack and pad arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')\n",
    "\n",
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)\n",
    "\n",
    "def pad_array(a, maxlen, value=0., dtype='float64'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = np.array(s[:maxlen]).astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, filepath, feature_dict = {}, label='label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict)==0:\n",
    "            feature_dict['points'] = ['eta_array', 'phi_array']\n",
    "            feature_dict['features'] = ['eta_array', 'phi_array', 'pT_array']\n",
    "            feature_dict['mask'] = ['pT_array']\n",
    "            #\"eta_array\": b,\"phi_array\": c,\"pT_array\"\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "        counts = None\n",
    "        with awkward0.load(self.filepath) as a:\n",
    "            \n",
    "            self._label = a[self.label]\n",
    "            for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    if counts is None:\n",
    "                        counts = awkward.count(a[col],axis=None)\n",
    "                    else:\n",
    "                        assert np.array_equal(counts, awkward.count(a[col],axis=None))\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "Change path to your train dataset ( train + validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-22 22:47:41,262] INFO: Start loading file /software/dg22882/ParticleNet/Dataset/150000_max_sorted_train_dataset_experiments_abseta3.awkd\n",
      "[2022-08-22 22:47:55,589] INFO: Finished loading file /software/dg22882/ParticleNet/Dataset/150000_max_sorted_train_dataset_experiments_abseta3.awkd\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('/software/dg22882/ParticleNet/Dataset/150000_max_sorted_train_dataset_experiments_abseta3.awkd', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 22:47:57.433639: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 22:48:01.854932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13578 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2022-08-22 22:48:01.857083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13578 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5\n",
      "2022-08-22 22:48:01.859011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13578 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:5f:00.0, compute capability: 7.5\n",
      "2022-08-22 22:48:01.860874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13578 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:88:00.0, compute capability: 7.5\n",
      "2022-08-22 22:48:01.862713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 13578 MB memory:  -> device: 4, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5\n",
      "2022-08-22 22:48:01.864656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 13578 MB memory:  -> device: 5, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_exp_19'        #set your model (file) name\n",
    "num_classes = 2                    #our task is binary classification so we only have two classes\n",
    "input_shapes = {k:np.shape(dataset[k])[1:] for k in dataset.X}\n",
    "model = get_particle_net_lite(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Strategy\n",
    "We have two learning rate strategy: <b>constant learning rate</b> and <b>learning rate decay</b>.\n",
    "\n",
    "Also set up your <b>batch size</b> here.\n",
    "\n",
    "If you want to use <b>learning rate decay</b> strategy, don't forget to enter your number of training epochs and validation split ratio here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def lr_schedule(lr):\\n    lr = lr\\n    return lr'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "validation_split=0.25\n",
    "num_train_steps = (len(dataset['points'])*(1-validation_split) // batch_size) * num_epochs\n",
    "\n",
    "#Polynomial lr Decay\n",
    "def lr_schedule(initial_learning_rate,end_learning_rate):\n",
    "    lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "       initial_learning_rate = initial_learning_rate,\n",
    "       end_learning_rate = end_learning_rate,\n",
    "       decay_steps = num_train_steps)\n",
    "    return lr\n",
    "\n",
    "#If you want to use constant lr, activate this function and deactivate the above one\n",
    "'''def lr_schedule(lr):\n",
    "    lr = lr\n",
    "    return lr'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up optimizer and Learning rate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " mask (InputLayer)              [(None, 100, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 100, 1)      0           ['mask[0][0]']                   \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 100, 1)       0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.equal (TFOpLambda)     (None, 100, 1)       0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 100, 1)       0           ['tf.math.equal[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 100, 1)       0           ['tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " points (InputLayer)            [(None, 100, 2)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 100, 2)       0           ['tf.math.multiply[0][0]',       \n",
      "                                                                  'points[0][0]']                 \n",
      "                                                                                                  \n",
      " features (InputLayer)          [(None, 100, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 2, 100)      0           ['tf.math.add[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 100, 1, 3)    0           ['features[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 100, 2)      0           ['tf.math.add[0][0]',            \n",
      " )                                                                'tf.math.add[0][0]']            \n",
      "                                                                                                  \n",
      " tf.linalg.matmul (TFOpLambda)  (None, 100, 100)     0           ['tf.math.add[0][0]',            \n",
      "                                                                  'tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 100, 2)      0           ['tf.math.add[0][0]',            \n",
      " )                                                                'tf.math.add[0][0]']            \n",
      "                                                                                                  \n",
      " ParticleNet_fts_bn (BatchNorma  (None, 100, 1, 3)   12          ['tf.expand_dims[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 100, 1)      0           ['tf.math.multiply_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 100, 100)    0           ['tf.linalg.matmul[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 100, 1)      0           ['tf.math.multiply_2[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 100, 3)      0           ['ParticleNet_fts_bn[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 100, 100)     0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 1, 100)      0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['tf.compat.v1.squeeze[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 100, 100)    0           ['tf.math.subtract[0][0]',       \n",
      " da)                                                              'tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None, 100, 100)     0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.range (TFOpLambda)          (None,)              0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.top_k (TFOpLambda)     TopKV2(values=(None  0           ['tf.math.negative[0][0]']       \n",
      "                                , 100, 8),                                                        \n",
      "                                 indices=(None, 100                                               \n",
      "                                , 8))                                                             \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1, 1, 1)      0           ['tf.range[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 100, 7)      0           ['tf.math.top_k[0][1]']          \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (None, 100, 7, 1)    0           ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 100, 7, 1)    0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 100, 1, 3)    0           ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 100, 7, 2)    0           ['tf.tile[0][0]',                \n",
      "                                                                  'tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.tile_1 (TFOpLambda)         (None, 100, 7, 3)    0           ['tf.expand_dims_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd (TFOpLa  (None, 100, 7, 3)   0           ['tf.compat.v1.squeeze[0][0]',   \n",
      " mbda)                                                            'tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 100, 7, 3)   0           ['tf.compat.v1.gather_nd[0][0]', \n",
      " )                                                                'tf.tile_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 100, 7, 6)    0           ['tf.tile_1[0][0]',              \n",
      "                                                                  'tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_conv0 (C  (None, 100, 7, 4)   24          ['tf.concat_1[0][0]']            \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_bn0 (Bat  (None, 100, 7, 4)   16          ['ParticleNet_EdgeConv0_conv0[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_act0 (Ac  (None, 100, 7, 4)   0           ['ParticleNet_EdgeConv0_bn0[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_conv1 (C  (None, 100, 7, 4)   16          ['ParticleNet_EdgeConv0_act0[0][0\n",
      " onv2D)                                                          ]']                              \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_bn1 (Bat  (None, 100, 7, 4)   16          ['ParticleNet_EdgeConv0_conv1[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_act1 (Ac  (None, 100, 7, 4)   0           ['ParticleNet_EdgeConv0_bn1[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 100, 1, 3)    0           ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_conv2 (C  (None, 100, 7, 4)   16          ['ParticleNet_EdgeConv0_act1[0][0\n",
      " onv2D)                                                          ]']                              \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_sc_conv   (None, 100, 1, 4)   12          ['tf.expand_dims_3[0][0]']       \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_bn2 (Bat  (None, 100, 7, 4)   16          ['ParticleNet_EdgeConv0_conv2[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_sc_bn (B  (None, 100, 1, 4)   16          ['ParticleNet_EdgeConv0_sc_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_act2 (Ac  (None, 100, 7, 4)   0           ['ParticleNet_EdgeConv0_bn2[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TFOpLa  (None, 100, 4)      0           ['ParticleNet_EdgeConv0_sc_bn[0][\n",
      " mbda)                                                           0]']                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 100, 4)      0           ['ParticleNet_EdgeConv0_act2[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 100, 4)      0           ['tf.compat.v1.squeeze_1[0][0]', \n",
      " mbda)                                                            'tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv0_sc_act (  (None, 100, 4)      0           ['tf.__operators__.add_1[0][0]'] \n",
      " Activation)                                                                                      \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)     (None, 100, 4)       0           ['tf.math.multiply[0][0]',       \n",
      "                                                                  'ParticleNet_EdgeConv0_sc_act[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (TFOp  (None, 4, 100)      0           ['tf.math.add_1[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 100, 4)      0           ['tf.math.add_1[0][0]',          \n",
      " )                                                                'tf.math.add_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLambda  (None, 100, 100)    0           ['tf.math.add_1[0][0]',          \n",
      " )                                                                'tf.compat.v1.transpose_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 100, 4)      0           ['tf.math.add_1[0][0]',          \n",
      " )                                                                'tf.math.add_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  (None, 100, 1)      0           ['tf.math.multiply_4[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 100, 100)    0           ['tf.linalg.matmul_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  (None, 100, 1)      0           ['tf.math.multiply_5[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 100, 100)    0           ['tf.math.reduce_sum_2[0][0]',   \n",
      " )                                                                'tf.math.multiply_6[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (TFOp  (None, 1, 100)      0           ['tf.math.reduce_sum_3[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOpLamb  (3,)                0           ['ParticleNet_EdgeConv0_sc_act[0]\n",
      " da)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 100, 100)    0           ['tf.math.subtract_2[0][0]',     \n",
      " mbda)                                                            'tf.compat.v1.transpose_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.negative_1 (TFOpLambda  (None, 100, 100)    0           ['tf.__operators__.add_2[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.range_1 (TFOpLambda)        (None,)              0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.top_k_1 (TFOpLambda)   TopKV2(values=(None  0           ['tf.math.negative_1[0][0]']     \n",
      "                                , 100, 8),                                                        \n",
      "                                 indices=(None, 100                                               \n",
      "                                , 8))                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 1, 1, 1)      0           ['tf.range_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 100, 7)      0           ['tf.math.top_k_1[0][1]']        \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.tile_2 (TFOpLambda)         (None, 100, 7, 1)    0           ['tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 100, 7, 1)    0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 100, 1, 4)    0           ['ParticleNet_EdgeConv0_sc_act[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 100, 7, 2)    0           ['tf.tile_2[0][0]',              \n",
      "                                                                  'tf.expand_dims_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.tile_3 (TFOpLambda)         (None, 100, 7, 4)    0           ['tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_nd_1 (TFOp  (None, 100, 7, 4)   0           ['ParticleNet_EdgeConv0_sc_act[0]\n",
      " Lambda)                                                         [0]',                            \n",
      "                                                                  'tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 100, 7, 4)   0           ['tf.compat.v1.gather_nd_1[0][0]'\n",
      " )                                                               , 'tf.tile_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 100, 7, 8)    0           ['tf.tile_3[0][0]',              \n",
      "                                                                  'tf.math.subtract_3[0][0]']     \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_conv0 (C  (None, 100, 7, 8)   64          ['tf.concat_3[0][0]']            \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_bn0 (Bat  (None, 100, 7, 8)   32          ['ParticleNet_EdgeConv1_conv0[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_act0 (Ac  (None, 100, 7, 8)   0           ['ParticleNet_EdgeConv1_bn0[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_conv1 (C  (None, 100, 7, 8)   64          ['ParticleNet_EdgeConv1_act0[0][0\n",
      " onv2D)                                                          ]']                              \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_bn1 (Bat  (None, 100, 7, 8)   32          ['ParticleNet_EdgeConv1_conv1[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_act1 (Ac  (None, 100, 7, 8)   0           ['ParticleNet_EdgeConv1_bn1[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 100, 1, 4)    0           ['ParticleNet_EdgeConv0_sc_act[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_conv2 (C  (None, 100, 7, 8)   64          ['ParticleNet_EdgeConv1_act1[0][0\n",
      " onv2D)                                                          ]']                              \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_sc_conv   (None, 100, 1, 8)   32          ['tf.expand_dims_6[0][0]']       \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_bn2 (Bat  (None, 100, 7, 8)   32          ['ParticleNet_EdgeConv1_conv2[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_sc_bn (B  (None, 100, 1, 8)   32          ['ParticleNet_EdgeConv1_sc_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_act2 (Ac  (None, 100, 7, 8)   0           ['ParticleNet_EdgeConv1_bn2[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_2 (TFOpLa  (None, 100, 8)      0           ['ParticleNet_EdgeConv1_sc_bn[0][\n",
      " mbda)                                                           0]']                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 100, 8)      0           ['ParticleNet_EdgeConv1_act2[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 100, 8)      0           ['tf.compat.v1.squeeze_2[0][0]', \n",
      " mbda)                                                            'tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " ParticleNet_EdgeConv1_sc_act (  (None, 100, 8)      0           ['tf.__operators__.add_3[0][0]'] \n",
      " Activation)                                                                                      \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 100, 8)      0           ['ParticleNet_EdgeConv1_sc_act[0]\n",
      " )                                                               [0]',                            \n",
      "                                                                  'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 8)           0           ['tf.math.multiply_7[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           144         ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            17          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 657\n",
      "Trainable params: 555\n",
      "Non-trainable params: 102\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0.01,0.001)),    #you can change optimizer and lr here\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=f'/software/dg22882/ParticleNet/model_record/{model_name}',           #filepath\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=10,\n",
    "                             save_best_only=True)         \n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, progress_bar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Set <b>number of training epochs</b> and set <b>ratio</b> to split Dataset for training set and testing set. Start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 22:48:07.105087: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2022-08-22 22:48:08.558399: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.2.89, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/Unknown - 49s 0s/sample - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99933, saving model to /software/dg22882/ParticleNet/model_record/model_exp_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 22:49:07.484236: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /software/dg22882/ParticleNet/model_record/model_exp_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-22 22:49:09,147] INFO: Assets written to: /software/dg22882/ParticleNet/model_record/model_exp_19/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758/1758 [==============================] - 64s 37ms/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 2: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 54s 31ms/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 3/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 3: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 55s 31ms/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 4: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 54s 31ms/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1090 - val_accuracy: 0.9424\n",
      "Epoch 5/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 5: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 54s 31ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 6: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 55s 31ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3285 - val_accuracy: 0.8460\n",
      "Epoch 7/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 7: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 55s 31ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0116 - val_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 8: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 54s 31ms/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0826 - val_accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 9: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 53s 30ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "   0/1758 [..............................] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 10: val_accuracy did not improve from 0.99933\n",
      "1758/1758 [==============================] - 53s 30ms/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0246 - val_accuracy: 0.9969\n",
      "INFO:tensorflow:Assets written to: /software/dg22882/ParticleNet/model_record/model_exp_19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-22 22:57:17,508] INFO: Assets written to: /software/dg22882/ParticleNet/model_record/model_exp_19/assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.X, dataset.y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,                                                    # --- set number of training epochs ---      \n",
    "          validation_split=0.25,                                        # --- set ratio to split Dataset for training set and testing set ---\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.save(f\"/software/dg22882/ParticleNet/model_record/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Set <b>testing dataset file path</b> here. Also we will save prediction scores which use to make plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics saved: model_exp_19\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save training metrics\n",
    "metrics = dict(history.history)\n",
    "with open(f\"/software/dg22882/ParticleNet/model_record/{model_name}/model_metrics.pickle\", 'wb') as handle:\n",
    "        pickle.dump(metrics , handle, protocol=4)\n",
    "print(f\"metrics saved: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-22 23:03:19,262] INFO: Start loading file /software/dg22882/ParticleNet/Dataset/50000_max_sorted_test_dataset_experiments_abseta3.awkd\n",
      "[2022-08-22 23:03:23,723] INFO: Finished loading file /software/dg22882/ParticleNet/Dataset/50000_max_sorted_test_dataset_experiments_abseta3.awkd\n"
     ]
    }
   ],
   "source": [
    "# Predict on test dataset\n",
    "# Change path to testing dataset here\n",
    "test_dataset = Dataset('/software/dg22882/ParticleNet/Dataset/50000_max_sorted_test_dataset_experiments_abseta3.awkd', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy files to use in make_plots2.py\n",
    "scores = np.array(model.predict(test_dataset.X)).astype(np.float64)\n",
    "np.save(f'/software/dg22882/ParticleNet/model_record/{model_name}/prediction_scores.npy', scores)\n",
    "np.save('/software/dg22882/ParticleNet/Dataset/test_labels.npy', test_dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.1603e+04, 1.4000e+03, 7.9900e+02, 5.8500e+02, 3.6000e+02,\n",
       "        1.2700e+02, 5.1000e+01, 2.3000e+01, 2.2000e+01, 2.5030e+04]),\n",
       " array([4.07159358e-04, 1.00366408e-01, 2.00325656e-01, 3.00284904e-01,\n",
       "        4.00244153e-01, 5.00203401e-01, 6.00162649e-01, 7.00121897e-01,\n",
       "        8.00081146e-01, 9.00040394e-01, 9.99999642e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('ml_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b560b6b8654ff80c2423d7d34d24b3c2414182d2a0d3efa64f303717b59a940c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
